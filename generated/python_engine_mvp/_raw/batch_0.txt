```json
{
  "files": [
    {
      "path": "python_engine/main.py",
      "content": "#!/usr/bin/env python3\n\"\"\"Main entry point for PDF parsing engine.\n\nUsage:\n    python python_engine/main.py --pdf <path_to_pdf>\n\nOutputs JSON to stdout with parsed invoice data.\n\"\"\"\n\nimport argparse\nimport json\nimport sys\nfrom pathlib import Path\n\nfrom ocr_stub import ocr_extract_text\nfrom parser import parse_invoice_data\nfrom normalizer import normalize_item_name, classify_cost_type\n\n\ndef main():\n    parser = argparse.ArgumentParser(description='Parse PDF invoice and output JSON')\n    parser.add_argument('--pdf', required=True, help='Path to PDF file')\n    args = parser.parse_args()\n    \n    pdf_path = Path(args.pdf)\n    if not pdf_path.exists():\n        print(json.dumps({\"error\": f\"File not found: {pdf_path}\"}), file=sys.stderr)\n        sys.exit(1)\n    \n    # Step 1: Extract text from PDF (OCR stub)\n    raw_text = ocr_extract_text(str(pdf_path))\n    \n    # Step 2: Parse invoice data from raw text\n    parsed_data = parse_invoice_data(raw_text)\n    \n    # Step 3: Normalize item names and classify cost types\n    normalized_items = []\n    for item in parsed_data.get('items', []):\n        normalized_item = {\n            \"item_name_raw\": item['item_name_raw'],\n            \"item_name_norm\": normalize_item_name(item['item_name_raw']),\n            \"cost_type\": classify_cost_type(item['item_name_raw']),\n            \"amount_excl_tax\": item['amount_excl_tax']\n        }\n        normalized_items.append(normalized_item)\n    \n    # Step 4: Build final output JSON\n    output = {\n        \"vendor_name\": parsed_data.get('vendor_name', ''),\n        \"estimate_date\": parsed_data.get('estimate_date', ''),\n        \"total_excl_tax\": parsed_data.get('total_excl_tax', 0),\n        \"total_incl_tax\": parsed_data.get('total_incl_tax', 0),\n        \"items\": normalized_items\n    }\n    \n    # Output JSON to stdout\n    print(json.dumps(output, ensure_ascii=False, indent=2))\n\n\nif __name__ == '__main__':\n    main()\n"
    },
    {
      "path": "python_engine/ocr_stub.py",
      "content": "\"\"\"OCR stub module.\n\nReturns mock OCR results for testing purposes.\nIn production, this would integrate with actual OCR services.\n\"\"\"\n\n\ndef ocr_extract_text(pdf_path: str) -> str:\n    \"\"\"Extract text from PDF using OCR.\n    \n    Args:\n        pdf_path: Path to the PDF file\n        \n    Returns:\n        Extracted text as string (stub data for now)\n    \"\"\"\n    # Stub implementation returns mock invoice data\n    stub_text = \"\"\"株式会社サンプル自動車\n見積日: 2024-01-15\n\n品目:\n1. ワイパーブレード交換 3,500円\n2. エンジンオイル 4L 8,000円\n3. オイルフィルター 1,200円\n4. オイル交換工賃 2,000円\n5. ブレーキパッド 12,000円\n6. ブレーキパッド交換工賃 5,000円\n\n小計（税抜）: 31,700円\n消費税（10%）: 3,170円\n合計（税込）: 34,870円\n\"\"\"\n    return stub_text\n"
    },
    {
      "path": "python_engine/parser.py",
      "content": "\"\"\"Parser module for extracting structured data from OCR text.\"\"\"\n\nimport re\nfrom typing import Dict, List, Any\n\n\ndef parse_invoice_data(raw_text: str) -> Dict[str, Any]:\n    \"\"\"Parse invoice data from raw OCR text.\n    \n    Args:\n        raw_text: Raw text extracted from PDF\n        \n    Returns:\n        Dictionary with parsed invoice data\n    \"\"\"\n    result = {\n        'vendor_name': '',\n        'estimate_date': '',\n        'total_excl_tax': 0,\n        'total_incl_tax': 0,\n        'items': []\n    }\n    \n    # Extract vendor name (first line typically)\n    lines = raw_text.strip().split('\\n')\n    if lines:\n        result['vendor_name'] = lines[0].strip()\n    \n    # Extract estimate date\n    date_match = re.search(r'見積日[:\\s：]+(\\d{4}[-/]\\d{1,2}[-/]\\d{1,2})', raw_text)\n    if date_match:\n        result['estimate_date'] = date_match.group(1)\n    \n    # Extract items with amounts\n    item_pattern = r'(?:\\d+\\.\\s+)?(.+?)\\s+(\\d{1,3}(?:,\\d{3})*)円'\n    items = re.findall(item_pattern, raw_text)\n    \n    for item_name, amount_str in items:\n        item_name = item_name.strip()\n        amount = int(amount_str.replace(',', ''))\n        \n        # Skip total/subtotal lines\n        if any(keyword in item_name for keyword in ['小計', '合計', '消費税']):\n            continue\n        \n        result['items'].append({\n            'item_name_raw': item_name,\n            'amount_excl_tax': amount\n        })\n    \n    # Extract totals\n    total_excl_match = re.search(r'小計[^\\d]*(\\d{1,3}(?:,\\d{3})*)円', raw_text)\n    if total_excl_match:\n        result['total_excl_tax'] = int(total_excl_match.group(1).replace(',', ''))\n    \n    total_incl_match = re.search(r'合計[^\\d]*(\\d{1,3}(?:,\\d{3})*)円', raw_text)\n    if total_incl_match:\n        result['total_incl_tax'] = int(total_incl_match.group(1).replace(',', ''))\n    \n    return result\n"
    },
    {
      "path": "python_engine/normalizer.py",
      "content": "\"\"\"Normalizer module for item names and cost type classification.\"\"\"\n\nimport re\n\n\ndef normalize_item_name(raw_name: str) -> str:\n    \"\"\"Normalize item names to standard format.\n    \n    Args:\n        raw_name: Raw item name from invoice\n        \n    Returns:\n        Normalized item name\n    \"\"\"\n    raw_name_lower = raw_name.lower()\n    \n    # Wiper blade normalization\n    wiper_keywords = ['ワイパー', 'wiper', 'ブレード']\n    for keyword in wiper_keywords:\n        if keyword in raw_name_lower:\n            return 'wiper_blade'\n    \n    # Return original if no normalization rule matches\n    return raw_name\n\n\ndef classify_cost_type(item_name: str) -> str:\n    \"\"\"Classify item as parts or labor.\n    \n    Args:\n        item_name: Item name (raw or normalized)\n        \n    Returns:\n        Cost type: 'parts' or 'labor'\n    \"\"\"\n    # Labor classification\n    if '工賃' in item_name:\n        return 'labor'\n    \n    # Default to parts\n    return 'parts'\n"
    },
    {
      "path": "python_engine/requirements.txt",
      "content": "# Python Engine Requirements\n# No external dependencies required for MVP\n# All functionality uses Python standard library\n"
    },
    {
      "path": "python_engine/README.md",
      "content": "# Python Engine for PDF Invoice Parsing\n\n## Overview\n\nThis is a stateless Python engine that parses PDF invoices and outputs structured JSON data. It is designed to be called from Rails applications.\n\n## Features\n\n- PDF text extraction via OCR (stub implementation)\n- Invoice data parsing (vendor, date, totals, line items)\n- Item name normalization (e.g., wiper-related terms → `wiper_blade`)\n- Cost type classification (`parts` vs `labor`)\n- JSON output to stdout\n\n## Installation\n\n```bash\npip install -r requirements.txt\n```\n\n## Usage\n\n```bash\npython python_engine/main.py --pdf dummy.pdf\n```\n\n### Output Format\n\n```json\n{\n  \"vendor_name\": \"株式会社サンプル自動車\",\n  \"estimate_date\": \"2024-01-15\",\n  \"total_excl_tax\": 31700,\n  \"total_incl_tax\": 34870,\n  \"items\": [\n    {\n      \"item_name_raw\": \"ワイパーブレード交換\",\n      \"item_name_norm\": \"wiper_blade\",\n      \"cost_type\": \"parts\",\n      \"amount_excl_tax\": 3500\n    },\n    {\n      \"item_name_raw\": \"オイル交換工賃\",\n      \"item_name_norm\": \"オイル交換工賃\",\n      \"cost_type\": \"labor\",\n      \"amount_excl_tax\": 2000\n    }\n  ]\n}\n```\n\n## Architecture\n\n### Modules\n\n- **main.py**: Entry point, orchestrates the parsing pipeline\n- **ocr_stub.py**: OCR stub that returns mock text data\n- **parser.py**: Extracts structured data from raw text\n- **normalizer.py**: Normalizes item names and classifies cost types\n\n### Design Principles\n\n- **Stateless**: No database, file system, or external service dependencies\n- **Stdout output**: Results written to stdout as JSON\n- **Modular**: Separated concerns for easy testing and extension\n\n## Normalization Rules\n\n### Item Names\n\n- `ワイパー`, `wiper`, `ブレード` → `wiper_blade`\n- Other items remain unchanged\n\n### Cost Types\n\n- Contains `工賃` → `labor`\n- Otherwise → `parts`\n\n## Testing\n\nCreate a dummy PDF file and run:\n\n```bash\ntouch dummy.pdf\npython python_engine/main.py --pdf dummy.pdf\n```\n\n## Future Enhancements\n\n- Real OCR integration (Tesseract, Google Vision API, etc.)\n- More sophisticated parsing logic\n- Additional normalization rules\n- Error handling and validation\n- Unit tests\n\n## License\n\nInternal use only.\n"
    }
  ],
  "notes": "Created MVP Python engine with main.py as entry point, OCR stub, parser, normalizer modules. Supports CLI args, outputs JSON to stdout, implements wiper_blade normalization and labor/parts classification."
}
```